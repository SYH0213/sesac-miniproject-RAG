{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18 pages.\n",
      "Gemini 2.5: Pushing the Frontier with\n",
      "Advanced Reasoning, Multimodality, Long\n",
      "Context, and Next Generation Agentic\n",
      "Capabilities.\n",
      "Gemini Team, Google\n",
      "In this report, we introduce the Gemini 2.X model f\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "pdf_path = \"data/gemini-2.5-tech.pdf\"\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "text_content = []\n",
    "for i in range(0, 18):  # Pages are 0-indexed\n",
    "    page = reader.pages[i]\n",
    "    text_content.append(page.extract_text())\n",
    "\n",
    "print(f\"Loaded {len(text_content)} pages.\")\n",
    "print(text_content[0][:200]) # Print first 200 characters of the first page to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18 pages.\n",
      "--- Page 13 ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "Capability BenchmarkFlashGemini 1.5\n",
      "ProGemini 1.5\n",
      "Flash-LiteGemini 2.0\n",
      "FlashGemini 2.0\n",
      "FlashGemini 2.5\n",
      "ProGemini 2.5\n",
      "CodeLiveCodeBench 30.3% 29.7% 29.1% 29.1% 59.3% 74.2%\n",
      "Aider Polyglot 2.8% 16.9% 10.5% 21.3% 56.7% 82.2%\n",
      "VerifiedSWE-benchattemptsingle9.6% 22.3% 12.5% 21.4% 48.9% 59.6%\n",
      "attemptsmultiple19.7% 34.2% 23.1% 34.2% 60.3% 67.2%\n",
      "Reasoning(diamond)GPQA50.0% 58.1% 50.5% 65.2% 82.8% 86.4%\n",
      "Last ExamHumanity’sno tools - 4.6% 4.6% † 5.1%† 11.0% 21.6%\n",
      "FactualitySimpleQA 8.6% 24.9% 16.5% 29.9% 26.9% 54.0%\n",
      "GroundingFACTS82.9% 80.0% 82.4% 84.6% 85.3% 87.8%\n",
      "Multilinguality (Lite)Global MMLU72.5% 80.8% 78.0% 83.4% 88.4% 89.2%\n",
      "ECLeKTic 16.4% 27.0% 27.7% 33.6% 36.8% 46.8%\n",
      "MathAIME 2025 14.7% 17.5% 23.8% 29.7% 72.0% 88.0%\n",
      "HiddenMath-\n",
      "Hard36.8% 44.3% 47.4% 53.7% 75.5% 80.5%\n",
      "Long-contextretrieval)LOFT (hard ≤128K 67.3% 75.9% 50.7% 58.0% 82.1% 87.0%\n",
      "1M 36.7% 47.1% 7.6% 7.6% 58.9% 69.8%\n",
      "(8-needle)MRCR-V2 ≤128K 18.4% 26.2% 11.6% 19.0% 54.3% 58.0%\n",
      "1M 10.2% 12.1% 4.0% 5.3% 21.0% 16.4%\n",
      "UnderstandingImageMMMU 58.3% 67.7% 65.1% 69.3% 79.7% 82.0%\n",
      "(Reka)Vibe-Eval52.3% 55.9% 51.5% 55.4% 65.4% 67.2%\n",
      "ZeroBench 0.5% 1.0% 0.75% 1.25% 2.0% 4.5%\n",
      "BetterChartQA 59.0% 65.8% 52.3% 57.8% 67.3% 72.4%\n",
      "Table 3|Evaluation of Gemini 2.5 family across a wide range of core capability benchmarks and in\n",
      "comparison to Gemini 1.5 models. Please see Tables 5 and 6 for audio and video evaluations. See\n",
      "Table 11 Appendix 8.1 for benchmarks and evaluation details.\n",
      "13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "pdf_path = \"data/gemini-2.5-tech.pdf\"\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "text_content = []\n",
    "for i in range(0, 18):  # Pages are 0-indexed\n",
    "    page = reader.pages[i]\n",
    "    text_content.append(page.extract_text())\n",
    "\n",
    "print(f\"Loaded {len(text_content)} pages.\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        page_num_input = input(f\"Enter page number (1-{len(text_content)}) or 'q' to quit: \")\n",
    "        if page_num_input.lower() == 'q':\n",
    "            break\n",
    "        \n",
    "        page_num = int(page_num_input)\n",
    "        if 1 <= page_num <= len(text_content):\n",
    "            print(f\"--- Page {page_num} ---\")\n",
    "            print(text_content[page_num - 1]) # Pages are 0-indexed in list\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(\"Invalid page number. Please try again.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number or 'q'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\")\n",
    "\n",
    "\n",
    "def pdf_parser(pdf_file_path: str):\n",
    "    \"\"\"\n",
    "    PDF 파일을 파싱하여 그 내용을 Markdown 파일로 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): 처리할 PDF 파일의 경로.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 '{pdf_file_path}' 파일 파싱을 시작합니다...\")\n",
    "\n",
    "    try:\n",
    "        # parsing instruction 을 지정합니다.\n",
    "        parsing_instruction = (\n",
    "            \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    "        )\n",
    "\n",
    "        # LlamaParse 설정\n",
    "        parser = LlamaParse(\n",
    "            use_vendor_multimodal_model=True,\n",
    "            vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "            vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            result_type=\"markdown\",\n",
    "            # parsing_mode=\"Unstructured\",\n",
    "            language=\"ko\",\n",
    "            parsing_instruction=parsing_instruction,\n",
    "        )\n",
    "\n",
    "        # 1. LlamaParse를 사용하여 PDF 파일을 로드합니다.\n",
    "        # 'documents' 객체는 이 함수 외부에서 미리 정의되어 있어야 합니다.\n",
    "        parsed_docs = documents.load_data(file_path=pdf_file_path)\n",
    "\n",
    "        # 2. LangChain 형식의 도큐먼트로 변환합니다.\n",
    "        docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "        # 3. 저장할 Markdown 파일의 경로를 생성합니다. (확장자 변경)\n",
    "        file_root, _ = os.path.splitext(pdf_file_path)\n",
    "        output_file_path = file_root + \".md\"\n",
    "\n",
    "        # 4. 모든 페이지의 내용을 하나의 텍스트로 합칩니다.\n",
    "        #    페이지 사이는 두 줄로 띄어 가독성을 높입니다.\n",
    "        full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # 5. 추출된 전체 텍스트를 .md 파일로 저장합니다.\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "\n",
    "        print(f\"✅ 파일 저장 완료: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 오류: 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "# --- 함수 사용 예시 ---\n",
    "# 이 코드를 실행하기 전에 'documents' 파서 객체를 초기화해야 합니다.\n",
    "# file_to_parse = \"data/디지털정부혁신추진계획.pdf\"\n",
    "file_to_parse = \"./data/lorem-ipsum-10pages.pdf\"\n",
    "pdf_parser(file_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Page 1 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with\n",
      "Advanced Reasoning, Multimodality, Long\n",
      "Context, and Next Generation Agentic\n",
      "Capabilities.\n",
      "Gemini Team, Google\n",
      "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well\n",
      "as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet,\n",
      "achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible\n",
      "coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding\n",
      "and it is now able to process up to 3 hours of video content. Its unique combination of long context,\n",
      "multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5\n",
      "Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and\n",
      "Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the\n",
      "Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to\n",
      "explore the boundaries of what is possible with complex agentic problem solving.\n",
      "1. Introduction\n",
      "We present our latest family of natively multimodal models with advanced reasoning through thinking,\n",
      "long context and tool-use capabilities: Gemini 2.5 Pro and 2.5 Flash and our earlier Gemini 2.0\n",
      "Flash and Gemini 2.0 Flash-Lite models. Together these form a new family of highly-capable models\n",
      "representing our next generation of AI models, designed to power a new era of agentic systems.\n",
      "Building upon the foundation of the Gemini 1.5 series (Gemini Team, 2024), this Gemini 2.X generation\n",
      "brings us closer to the vision of a universal AI assistant (Hassabis, 2025).\n",
      "The Gemini 2.X series are all built to be natively multimodal, supporting long context inputs of >1\n",
      "million tokens and have native tool use support. This allows them to comprehend vast datasets and\n",
      "handle complex problems from different information sources, including text, audio, images, video\n",
      "and even entire code repositories. These extensive capabilities can also be combined to build complex\n",
      "agentic systems, as happened in the case of Gemini Plays Pokémon1 (Zhang, 2025). Different models\n",
      "in the series have different strengths and capabilities: (1) Gemini 2.5 Pro is our most intelligent\n",
      "thinking model, exhibiting strong reasoning and code capabilities. It excels at producing interactive\n",
      "web applications, is capable of codebase-level understanding and also exhibits emergent multimodal\n",
      "coding abilities. (2) Gemini 2.5 Flash is our hybrid reasoning model with a controllable thinking\n",
      "budget, and is useful for most complex tasks while also controlling the tradeoff between quality, cost,\n",
      "and latency. (3) Gemini 2.0 Flash is our fast and cost-efficient non-thinking model for everyday tasks\n",
      "and (4) Gemini 2.0 Flash-Lite is our fastest and most cost-efficient model, built for at-scale usage. A\n",
      "full comparison of the models in the Gemini 2.X model family is provided in Table 1. Taken together,\n",
      "the Gemini 2.X family of models cover the whole Pareto frontier of model capability vs cost, shifting\n",
      "it forward across a large variety of core capabilities, applications and use-cases, see Figure 1.\n",
      "The Gemini 2.5 family of models maintain robust safety metrics while improving dramatically on\n",
      "1Pokémon is a trademark of Nintendo Co., Ltd., Creatures Inc., and Game Freak Inc.\n",
      "Please send correspondence to gemini-report@google.com.\n",
      "© 2025 Google. All rights reserved\n",
      "arXiv:2507.06261v4  [cs.CL]  22 Jul 2025\n",
      "\n",
      "\n",
      "\n",
      "Saved image: extracted_images\\page1_img0.png\n",
      "--- Page 2 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "Flash\n",
      "Gemini 1.5\n",
      "Pro\n",
      "Gemini 1.5\n",
      "Flash-Lite\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.5\n",
      "Pro\n",
      "Gemini 2.5\n",
      "Input modalities\n",
      "Video, Audio\n",
      "Text, Image,\n",
      "Video, Audio\n",
      "Text, Image,\n",
      "Video, Audio\n",
      "Text, Image,\n",
      "Video, Audio\n",
      "Text, Image,\n",
      "Video, Audio\n",
      "Text, Image,\n",
      "Video, Audio\n",
      "Text, Image,\n",
      "Input length\n",
      "1M\n",
      "2M\n",
      "1M\n",
      "1M\n",
      "1M\n",
      "1M\n",
      "Output modalities\n",
      "Text\n",
      "Text\n",
      "Text\n",
      "Text, Image*\n",
      "Text, Audio*\n",
      "Text, Audio*\n",
      "Output length\n",
      "8K\n",
      "8K\n",
      "8K\n",
      "8K\n",
      "64K\n",
      "64K\n",
      "Thinking\n",
      "No\n",
      "No\n",
      "No\n",
      "Yes*\n",
      "Dynamic\n",
      "Dynamic\n",
      "Supports tool use?\n",
      "No\n",
      "No\n",
      "No\n",
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "Knowledge cutoff\n",
      "November\n",
      "2023\n",
      "November\n",
      "2023\n",
      "June 2024\n",
      "June 2024\n",
      "January\n",
      "2025\n",
      "January\n",
      "2025\n",
      "Table 1 | Comparison of Gemini 2.X model family with Gemini 1.5 Pro and Flash. Tool use refers\n",
      "to the ability of the model to recognize and execute function calls (e.g., to perform web search,\n",
      "complete a math problem, execute code). *currently limited to Experimental or Preview, see Section 2.7.\n",
      "Information accurate as of publication date.\n",
      "helpfulness and general tone compared to their 2.0 and 1.5 counterparts. In practice, this means that\n",
      "the 2.5 models are substantially better at providing safe responses without interfering with important\n",
      "use cases or lecturing end users. We also evaluated Gemini 2.5 Pro’s Critical Capabilities, including\n",
      "CBRN, cybersecurity, machine learning R&D, and deceptive alignment. While Gemini 2.5 Pro showed\n",
      "a significant increase in some capabilities compared to previous Gemini models, it did not reach any\n",
      "of the Critical Capability Levels in any area.\n",
      "Our report is structured as follows: we begin by briefly describing advances we have made in\n",
      "model architecture, training and serving since the release of the Gemini 1.5 model. We then showcase\n",
      "the performance of the Gemini 2.5 models, including qualitative demonstrations of its abilities. We\n",
      "conclude by discussing the safety evaluations and implications of this model series.\n",
      "2. Model Architecture, Training and Dataset\n",
      "2.1. Model Architecture\n",
      "The Gemini 2.5 models are sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021;\n",
      "Fedus et al., 2021; Jiang et al., 2024; Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021;\n",
      "Shazeer et al., 2017) transformers (Vaswani et al., 2017) with native multimodal support for text,\n",
      "vision, and audio inputs. Sparse MoE models activate a subset of model parameters per input token\n",
      "by learning to dynamically route tokens to a subset of parameters (experts); this allows them to\n",
      "decouple total model capacity from computation and serving cost per token. Developments to the\n",
      "model architecture contribute to the significantly improved performance of Gemini 2.5 compared to\n",
      "Gemini 1.5 Pro (see Section 3). Despite their overwhelming success, large transformers and sparse\n",
      "MoE models are known to suffer from training instabilities (Chowdhery et al., 2022; Dehghani et al.,\n",
      "2023; Fedus et al., 2021; Lepikhin et al., 2020; Liu et al., 2020; Molybog et al., 2023; Wortsman\n",
      "et al., 2023; Zhai et al., 2023; Zhang et al., 2022). The Gemini 2.5 model series makes considerable\n",
      "progress in enhancing large-scale training stability, signal propagation and optimization dynamics,\n",
      "resulting in a considerable boost in performance straight out of pre-training compared to previous\n",
      "Gemini models.\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "--- Page 3 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "Figure 1 | Cost-performance plot. Gemini 2.5 Pro is a marked improvement over Gemini 1.5 Pro, and\n",
      "has an LMArena score that is over 120 points higher than Gemini 1.5 Pro. Cost is a weighted average\n",
      "of input and output tokens pricing per million tokens. Source: LMArena, imported on 2025-06-16.\n",
      "Gemini 2.5 models build on the success of Gemini 1.5 in processing long-context queries, and\n",
      "incorporate new modeling advances allowing Gemini 2.5 Pro to surpass the performance of Gemini\n",
      "1.5 Pro in processing long context input sequences of up to 1M tokens (see Table 3). Both Gemini 2.5\n",
      "Pro and Gemini 2.5 Flash can process pieces of long-form text (such as the entirety of “Moby Dick” or\n",
      "“Don Quixote”), whole codebases, and long form audio and video data (see Appendix 8.5). Together\n",
      "with advancements in long-context abilities, architectural changes to Gemini 2.5 vision processing\n",
      "lead to a considerable improvement in image and video understanding capabilities, including being\n",
      "able to process 3-hour-long videos and the ability to convert demonstrative videos into interactive\n",
      "coding applications (see our recent blog post by Baddepudi et al., 2025).\n",
      "The smaller models in the Gemini 2.5 series — Flash size and below — use distillation (Anil et al.,\n",
      "2018; Hinton et al., 2015), as was done in the Gemini 1.5 series (Gemini Team, 2024). To reduce\n",
      "the cost associated with storing the teacher’s next token prediction distribution, we approximate it\n",
      "using a k-sparse distribution over the vocabulary. While this still increases training data throughput\n",
      "and storage demands by a factor of k, we find this to be a worthwhile trade-off given the significant\n",
      "quality improvement distillation has on our smaller models, leading to high-quality models with a\n",
      "reduced serving cost (see Figure 2).\n",
      "2.2. Dataset\n",
      "Our pre-training dataset is a large-scale, diverse collection of data encompassing a wide range of\n",
      "domains and modalities, which includes publicly available web documents, code (various programming\n",
      "languages), images, audio (including speech and other audio types) and video, with a cutoff date\n",
      "of June 2024 for 2.0 and January 2025 for 2.5. Compared to the Gemini 1.5 pre-training dataset\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "Saved image: extracted_images\\page3_img0.png\n",
      "--- Page 4 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "Output Tokens per Second\n",
      "Gemini 2.5 Flash\n",
      "Gemini 2.0 Flash\n",
      "Gemini 2.0 Flash-Lite\n",
      "o4-mini (high)\n",
      "o3\n",
      "Gemini 2.5 Pro\n",
      "Grok 3\n",
      "Claude 4 Opus (Extended Thinking)\n",
      "Claude 4 Sonnet (Extended Thinking)\n",
      "DeepSeek R1 0528 (May '25)\n",
      "Company\n",
      "Google\n",
      "OpenAI\n",
      "Anthropic\n",
      "DeepSeek\n",
      "xAI\n",
      "Figure 2 | Number of output tokens generated per second (after the first chunk has been received\n",
      "from the API) for different models. Source: ArtificialAnalysis.ai, imported on 2025-06-15.\n",
      "we also utilized new methods for improved data quality for both filtering, and deduplication. Our\n",
      "post-training dataset, like Gemini 1.5, consists of instruction tuning data that is carefully collected\n",
      "and vetted. It is a collection of multimodal data with paired instructions and responses, in addition to\n",
      "human preference and tool-use data.\n",
      "2.3. Training Infrastructure\n",
      "This model family is the first to be trained on TPUv5p architecture. We employed synchronous\n",
      "data-parallel training to parallelise over multiple 8960-chip pods of Google’s TPUv5p accelerators,\n",
      "distributed across multiple datacenters.\n",
      "The main advances in software pre-training infrastructure compared with Gemini 1.5 were related\n",
      "to elasticity and mitigation of SDC (Silent Data Corruption) errors:\n",
      "1. Slice-Granularity Elasticity: Our system now automatically continues training with fewer\n",
      "“slices” of TPU chips when there is a localized failure, and this reconfiguration results in tens\n",
      "of seconds of lost training time per interruption, compared with the 10 or more minute delay\n",
      "waiting for healthy machines to be rescheduled without elasticity; the system continues training\n",
      "at around 97% throughput while the failed slice is recovering. At the scale of this training run\n",
      "we see interruptions from hardware failures multiple times per hour, but our fault tolerance\n",
      "machinery is designed to tolerate the higher failure rates expected at much larger scales.\n",
      "2. Split-Phase SDC Detection: On previous large-scale runs it could take many hours to detect\n",
      "and localize machines with SDC errors, requiring both downtime while debugging, and roll-\n",
      "back/replay of a large number of potentially corrupt training steps. We now use lightweight\n",
      "deterministic replay to immediately repeat any step with suspicious metrics, and compare\n",
      "per-device intermediate checksums to localize the root cause of any data corruption. Empirically,\n",
      "accelerators that start to exhibit intermittent SDCs are identified within a few minutes, and\n",
      "quickly excluded from the job. During this run, around 0.25% of steps were replayed due to\n",
      "suspected SDCs and 6% of these replays turned out to be genuine hardware corruption.\n",
      "Both of the above techniques were relatively simple to implement due to the single-controller\n",
      "design of the Pathways system (Barham et al., 2022), which allows all accelerators to be coordinated\n",
      "from a single python program with a global view of the system state. The controller can make use of\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "--- Page 5 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "Accuracy / Pass rate (%)\n",
      "AIME\n",
      "2.0 Flash (No Thinking)\n",
      "2.0 Flash (Thinking)\n",
      "2.5 Flash (Dynamic Thinking)\n",
      "2.5 Pro (Dynamic Thinking)\n",
      "GPQA (Diamond)\n",
      "LiveCodeBench v5\n",
      "Figure 3 | Impact of “Thinking” on Gemini’s performance on AIME 2025 (Balunović et al., 2025),\n",
      "LiveCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\n",
      "diamond (Rein et al., 2024) benchmarks.\n",
      "parallel ‘remote python’ operations on TPU workers to monitor training metrics, track performance\n",
      "stragglers, and root-cause SDC errors.\n",
      "Overall during the run, 93.4% of the time was spent performing TPU computations; the re-\n",
      "mainder was approximately spent half in elastic reconfigurations, and half in rare tail cases where\n",
      "elasticity failed. Around 4.5% of the computed steps were replays or rollbacks for model debugging\n",
      "interventions.\n",
      "2.4. Post-training\n",
      "Since the initial announcement of Gemini 1.5, significant advancements have been made in our\n",
      "post-training methodologies, driven by a consistent focus on data quality across the Supervised\n",
      "Fine-Tuning (SFT), Reward Modeling (RM), and Reinforcement Learning (RL) stages. A key focus\n",
      "has been leveraging the model itself to assist in these processes, enabling more efficient and nuanced\n",
      "quality control.\n",
      "Furthermore, we have increased the training compute allocated to RL, allowing deeper exploration\n",
      "and refinement of model behaviors. This has been coupled with a focus on verifiable rewards\n",
      "and model-based generative rewards to provide more sophisticated and scalable feedback signals.\n",
      "Algorithmic changes to the RL process have also improved stability during longer training. These\n",
      "advancements have enabled Gemini 2.5 to learn from more diverse and complex RL environments,\n",
      "including those requiring multi-step actions and tool use. The combination of these improvements in\n",
      "data quality, increased compute, algorithmic enhancements, and expanded capabilities has contributed\n",
      "to across-the-board performance gains (as described in Section 3) , notably reflected in the significant\n",
      "increase in the model’s LMArena Elo scores, with both Gemini 2.5 Flash and Pro gaining more than\n",
      "110 points over their Gemini 1.5 counterparts (122 for Gemini 2.5 Pro and 111 for Gemini 2.5 Flash,\n",
      "see Figure 1), along with significant improvements on several other frontier benchmarks.\n",
      "2.5. Thinking\n",
      "Past Gemini models produce an answer immediately following a user query. This constrains the\n",
      "amount of inference-time compute (Thinking) that our models can spend reasoning over a problem.\n",
      "Gemini Thinking models are trained with Reinforcement Learning to use additional compute at\n",
      "inference time to arrive at more accurate answers. The resulting models are able to spend tens of\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "--- Page 6 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "8192\n",
      "16384\n",
      "32768\n",
      "Thinking Budget (number of tokens)\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "Accuracy / Pass rate (%)\n",
      "AIME 2025\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "8192\n",
      "16384\n",
      "32768\n",
      "Thinking budget (number of tokens)\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "LiveCodeBench\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "8192\n",
      "16384\n",
      "32768\n",
      "Thinking budget (number of tokens)\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "GPQA diamond\n",
      "Figure 4 | Impact of thinking budget on performance on AIME 2025 (Balunović et al., 2025), Live-\n",
      "CodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\n",
      "diamond (Rein et al., 2024) benchmarks.\n",
      "thousands of forward passes during a “thinking” stage, before responding to a question or query.\n",
      "Our training recipe has evolved from the original experimental thinking model, Gemini 2.0 Flash\n",
      "Thinking (launched in December 2024), to the Gemini 2.5 Thinking series, which incorporates\n",
      "Thinking natively across all domains. The result is a single model that can achieve stronger reasoning\n",
      "performance across the board, and is able to scale up its performance further as a function of inference\n",
      "time (see Figure 3 for an example of the impact of Thinking).\n",
      "We integrated Thinking with other Gemini capabilities, including native multimodal inputs (images,\n",
      "text, video, audio) and long context (1M+ tokens). For any of these capabilities, the model decides\n",
      "for itself how long to think before providing an answer. We also provide the ability to set a Thinking\n",
      "budget, constraining the model to respond within a desired number of tokens. This allows users to\n",
      "trade off performance with cost. To demonstrate this capability, we conducted experiments where we\n",
      "systematically varied the thinking budget, measured in the number of tokens the model is allowed to\n",
      "use for internal computation. As shown in Figure 4, increasing this budget allows the model to scale\n",
      "its performance and achieve significantly higher accuracy.\n",
      "2.6. Capability-specific improvements\n",
      "While most of the changes made to our training architecture and recipe since Gemini 1.5 have resulted\n",
      "in improvements across all capabilities, we have also made changes that have resulted in some\n",
      "capability-specific wins. We will now discuss these for code, factuality, long context, multilinguality,\n",
      "audio, video, and agentic use cases (with a particular focus on Gemini Deep Research).\n",
      "Code\n",
      "Gemini 2.0 and 2.5 represent a strategic shift of our development priorities towards delivering\n",
      "tangible real-world value, empowering users to address practical challenges and achieve development\n",
      "objectives within today’s complex, multimodal software environments. To realize this, concerted\n",
      "efforts have been undertaken across both pre-training and post-training phases since Gemini 1.5.\n",
      "In pre-training, we intensified our focus on incorporating a greater volume and diversity of code\n",
      "data from both repository and web sources into the training mixture. This has rapidly expanded\n",
      "coverage and enabled the development of more compute-efficient models. Furthermore, we have\n",
      "substantially enhanced our suite of evaluation metrics for assessing code capabilities aligned with\n",
      "downstream use cases, alongside improving our ability to accurately predict model performance.\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "--- Page 7 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "During post-training, we developed novel training techniques incorporating reasoning capabilities and\n",
      "curated a diverse set of engineering tasks, with the aim to equip Gemini with effective problem-solving\n",
      "skills crucial for addressing modern engineering challenges. Key applications demonstrating these\n",
      "advancements include IDE functionalities, code agent use cases for complex, multi-step operations\n",
      "within full repositories, and multimodal, interactive scenarios such as end-to-end web and mobile\n",
      "application development. Collectively, these efforts have yielded broad and significant improvements\n",
      "in Gemini’s coding capabilities. This progress is evidenced by superior performance on established\n",
      "benchmarks: performance on LiveCodeBench (Jain et al., 2024) increased from 30.5% for Gemini\n",
      "1.5 Pro to 74.2% for Gemini 2.5 Pro, while that for Aider Polyglot (Gauthier, 2025) went from\n",
      "16.9% to 82.2%. Performance on SWEBench-verified (Chowdhury et al., 2024; Jimenez et al., 2024)\n",
      "went from 34.2% to 67.2%, see Table 3 and Figure 5 in Section 3.2. Furthermore, Gemini 2.5 Pro\n",
      "obtained an increase of over 500 Elo over Gemini 1.5 Pro on the LMArena WebDev Arena (Chiang\n",
      "et al., 2024; LMArena Team, 2025), resulting in meaningful enhancements in practical applications,\n",
      "including UI and web application development (Doshi, 2025a), and the creation of sophisticated\n",
      "agentic workflows (Kilpatrick, 2025).\n",
      "Factuality\n",
      "Within the context of generative models, ensuring the factuality of model responses to information-\n",
      "seeking prompts remains a core pillar of Gemini model development. With Gemini 1.5, our research\n",
      "was concentrated on enhancing the model’s world knowledge and its ability to provide answers\n",
      "faithfully grounded in the context provided within the prompt. This effort culminated in the December\n",
      "2024 release of FACTS Grounding (Jacovi et al., 2025), now an industry-standard benchmark for\n",
      "evaluating an LLM’s capacity to generate responses grounded in user-provided documents. With\n",
      "Gemini 2.0 and 2.5, we have significantly expanded our scope to address multimodal inputs, long-\n",
      "context reasoning, and model-retrieved information. At the same time, the landscape and user\n",
      "expectations for factuality have evolved dramatically, shaped in part by Google’s deployment of AI\n",
      "Overviews and AI Mode (Stein, 2025). To meet these demands, Gemini 2.0 marked a significant leap\n",
      "as our first model family trained to natively call tools like Google Search, enabling it to formulate\n",
      "precise queries and synthesize fresh information with sources. Building on this, Gemini 2.5 integrates\n",
      "advanced reasoning, allowing it to interleave these search capabilities with internal thought processes\n",
      "to answer complex, multi-hop queries and execute long-horizon tasks. The model has learned to use\n",
      "search and other tools, reason about the outputs, and issue additional, detailed follow-up queries\n",
      "to expand the information available to it and to verify the factual accuracy of the response. Our\n",
      "latest models now power the experiences of over 1.5B monthly active users in Google’s AI Overviews\n",
      "and 400M users in the Gemini App. These models exhibit state-of-the-art performance across a\n",
      "suite of factuality benchmarks, including SimpleQA for parametric knowledge (Wei et al., 2024),\n",
      "FACTS Grounding for faithfulness to provided documents (Jacovi et al., 2024, 2025), and the Vectara\n",
      "Hallucination Leaderboard (Hughes et al., 2023), cementing Gemini as the model of choice for\n",
      "information-seeking demands.\n",
      "Long context\n",
      "Modeling and data advances helped us improve the quality of our models’ responses to queries\n",
      "utilizing our one million-length context window, and we reworked our internal evaluations to be more\n",
      "challenging to help steer our modeling research. When hill-climbing, we targeted challenging retrieval\n",
      "tasks (like LOFT of Lee et al., 2024), long-context reasoning tasks (like MRCR-V2 of Vodrahalli et al.,\n",
      "2024), and multimodal tasks (like VideoMME of Fu et al., 2025). According to the results in Table 6,\n",
      "the new 2.5 models improve greatly over previous Gemini 1.5 models and achieve state-of-the-art\n",
      "quality on all of those. An example showcasing these improved capabilities for video recall can be\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "--- Page 8 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "seen in Appendix 8.5, where Gemini 2.5 Pro is able to consistently recall a 1 second visual event out\n",
      "of a full 46-minute video.2\n",
      "Multilinguality\n",
      "Gemini’s multilingual capabilities have also undergone a profound evolution since 1.5, which already\n",
      "encompassed over 400 languages via pretraining. This transformation stems from a holistic strategy,\n",
      "meticulously refining pre- and post-training data quality, advancing tokenization techniques, innovat-\n",
      "ing core modeling, and executing targeted capability hillclimbing. The impact is particularly striking\n",
      "in Indic and Chinese, Japanese and Korean languages, where dedicated optimizations in data quality\n",
      "and evaluation have unlocked dramatic gains in both quality and decoding speed. Consequently, users\n",
      "benefit from significantly enhanced language adherence, responses designed to faithfully respect the\n",
      "requested output language, and a robust improvement in generative quality and factuality across\n",
      "languages, solidifying Gemini’s reliability across diverse linguistic contexts.\n",
      "Audio\n",
      "While Gemini 1.5 was focused on native audio understanding tasks such as transcription, translation,\n",
      "summarization and question-answering, in addition to understanding, Gemini 2.5 was trained to\n",
      "perform audio generation tasks such as text-to-speech or native audio-visual to audio out dialog. To\n",
      "enable low-latency streaming dialog, we incorporated causal audio representations that also allow\n",
      "streaming audio into and out of Gemini 2.5. These capabilities derive from an increased amount of\n",
      "pre-training data spanning over 200 languages, and development of improved post-training recipes.\n",
      "Finally, through our improved post-training recipes, we have integrated advanced capabilities such as\n",
      "thinking, affective dialog, contextual awareness and tool use into Gemini’s native audio models.\n",
      "Video\n",
      "We have significantly expanded both our pretraining and post-training video understanding data,\n",
      "improving the audio-visual and temporal understanding capabilities of the model. We have also\n",
      "trained our models so that they perform competitively with 66 instead of 258 visual tokens per frame,\n",
      "enabling using about 3 hours of video instead of 1h within a 1M tokens context window3. Two\n",
      "new applications that were not previously possible, but that have been unlocked as a result of these\n",
      "changes are: creating an interactive app from a video (such as a quiz to test students’ understanding\n",
      "of the video content) and creating a p5.js animation to show the key concepts from the video. Our\n",
      "recent blog post (Baddepudi et al., 2025) shows examples of these applications.\n",
      "Gemini as an Agent: Deep Research\n",
      "Gemini Deep Research (Gemini Team, Google, 2024) is an agent built on top of the Gemini 2.5 Pro\n",
      "model designed to strategically browse the web and provide informed answers to even the most niche\n",
      "user queries. The agent is optimized to perform task prioritization, and is also able to identify when\n",
      "it reaches a dead-end when browsing. We have massively improved the capabilities of Gemini Deep\n",
      "Research since its initial launch in December 2024. As evidence of that, performance of Gemini\n",
      "Deep Research on the Humanity’s Last Exam benchmark (Phan et al., 2025) has gone from 7.95% in\n",
      "December 2024 to the SoTA score of 26.9% and 32.4% with higher compute (June 2025).\n",
      "2For further discussion on long context capabilities, challenges, and future outlook, the Release Notes podcast episode\n",
      "“Deep Dive into Long Context” provides additional insights and discussion: https://youtu.be/NHMJ9mqKeMQ.\n",
      "3This is referred to as low media resolution in the API: https://ai.google.dev/api/generate-content#Media\n",
      "Resolution.\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "--- Page 9 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "2.7. The path to Gemini 2.5\n",
      "On the way to Gemini 2.5 Pro, we experimented with our training recipe, and tested a small number\n",
      "of these experimental models with users. We have already discussed Gemini 2.0 Flash Thinking (see\n",
      "Section 2.5). We will now discuss some of the other models briefly.\n",
      "Gemini 2.0 Pro\n",
      "In February 2025, we released an experimental version of Gemini 2.0 Pro. At the time, it had\n",
      "the strongest coding performance of any model in the Gemini model family, as well as the best\n",
      "understanding and world knowledge. It also came with our largest context window at 2 million\n",
      "tokens, which enabled it to comprehensively analyze and understand vast amounts of information.\n",
      "For further information about Gemini 2.0 Pro, please see our earlier blog posts (Kavukcuoglu, 2025;\n",
      "Mallick and Kilpatrick, 2025).\n",
      "Gemini 2.0 Flash Native Image Generation Model\n",
      "In March 2025, we released an experimental version of Gemini 2.0 Flash Native Image Generation.\n",
      "It has brought to the users new capabilities as a result of a strong integration between the Gemini\n",
      "model and image-generation capabilities, enabling new experiences related to image generation &\n",
      "image editing via natural-language prompting. Capabilities such as multi-step conversational editing\n",
      "or interleaved text-image generation are very natural in such a setting, and horizontal transfer related\n",
      "to multi-language coverage immediately allowed such experiences to happen across all the languages\n",
      "supported by the Gemini models. Native image generation turns Gemini into a multimodal creation\n",
      "partner and enables Gemini to express ideas through both text and images, and to seamlessly move\n",
      "between the two. For further information about Gemini 2.0 Flash Native Image Generation, please\n",
      "see our earlier blog posts (Kampf and Brichtova, 2025; Sharon, 2025)\n",
      "Gemini 2.5 Audio Generation\n",
      "With Gemini 2.5, the Controllable TTS and Native Audio Dialog capabilities are available as separate\n",
      "options on AI Studio (Generate Media and Stream sections respectively). Our Gemini 2.5 Preview\n",
      "TTS Pro and Flash models support more than 80 languages with the speech style controlled by a free\n",
      "formatted prompt which can specify style, emotion, pace, etc, while also being capable of following\n",
      "finer-grained steering instructions specified in the transcript. Notably, Gemini 2.5 Preview TTS can\n",
      "generate speech with multiple speakers, which enables the creation of podcasts as used in NotebookLM\n",
      "Audio Overviews (Wang, 2024). Our Gemini 2.5 Flash Preview Native Audio Dialog model uses native\n",
      "audio generation, which enables the same level of style, pacing and accent control as available in our\n",
      "controllable TTS offering. Our dialog model supports tool use and function calling, and is available\n",
      "in more than 24 languages. With native audio understanding and generation capabilities, it can\n",
      "understand and respond appropriately to the user’s tone. This model is also capable of understanding\n",
      "when to respond to the user, and when not to respond, ignoring background and non-device directed\n",
      "audio. Finally, we also offer an advanced ‘Thinking’ variant that effectively handles more complex\n",
      "queries and provides more robust and reasoned responses in exchange for some additional latency.\n",
      "Gemini 2.5 Flash-Lite\n",
      "In June 2025, we released an experimental version of Gemini 2.5 Flash-Lite (gemini-2.5-flash-\n",
      "lite-preview-06-17). It comes with the same capabilities that make Gemini 2.5 helpful, including\n",
      "the ability to turn thinking on at different budgets, connecting to tools like Google Search and code\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "--- Page 10 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "execution, support for multimodal inputs and a 1 million-token context length. Our goal was to provide\n",
      "an economical model class which provides ultra-low-latency capabilities and high throughput per\n",
      "dollar, echoing the initial release of 2.0 Flash-Lite (Google DeepMind, 2025b; Mallick and Kilpatrick,\n",
      "2025).\n",
      "Gemini 2.5 Pro Deep Think\n",
      "To advance Gemini’s capabilities towards solving hard reasoning problems, we developed a novel\n",
      "reasoning approach, called Deep Think, that naturally blends in parallel thinking techniques during\n",
      "response generation. Deep Think enables Gemini to creatively produce multiple hypotheses and\n",
      "carefully critique them before arriving at the final answer, achieving state-of-the-art performances in\n",
      "challenging benchmarks such as Olympiad math (USAMO 2025), competitive coding (LiveCodeBench),\n",
      "and multimodality (MMMU), see more details at (Doshi, 2025b). We announced Gemini 2.5 Deep\n",
      "Think at Google I/O and launched an experimental version to trusted testers and advanced users in\n",
      "June 2025.\n",
      "10\n",
      "\n",
      "\n",
      "\n",
      "--- Page 11 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "3. Quantitative evaluation\n",
      "Flash\n",
      "Pro\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "Pass rate (%)\n",
      "LiveCodeBench\n",
      "Gemini version\n",
      "1.5\n",
      "2.0\n",
      "2.5\n",
      "Flash\n",
      "Pro\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "Aider Polyglot\n",
      "Flash\n",
      "Pro\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "SWE-bench Verified\n",
      "Flash\n",
      "Pro\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "Accuracy (%)\n",
      "GPQA (diamond)\n",
      "Flash\n",
      "Pro\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "AIME 2025\n",
      "Flash\n",
      "Pro\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "HiddenMath-Hard \n",
      "Figure 5 | Performance of Gemini 2.X models at coding, math and reasoning tasks in comparison to\n",
      "previous Gemini models. SWE-bench verified numbers correspond to the “multiple attempts” setting\n",
      "reported in Table 3.\n",
      "We will now examine the performance of the Gemini 2.X model family across a wide range of\n",
      "benchmarks. We will first compare the performance of the Gemini 2.X models to the earlier Gemini\n",
      "1.5 Pro and Flash models, before we compare the performance of Gemini 2.5 Pro to other available\n",
      "large language models.\n",
      "With web-scale pre-training of AI models, coupled with the post-training techniques that allow\n",
      "policy and reward models to leverage public benchmarks, avoiding leaks and biases in the data used\n",
      "for pre- and post-training is a persistent challenge. In the development of the Gemini 2.5 series, in\n",
      "addition to the standard n-gram based decontamination we used in Gemini 1.5, we also employed\n",
      "semantic-similarity and model based decontamination procedures to help mitigate evaluation set\n",
      "leakage. To move beyond the reliance on training set decontamination, we also continue reporting on\n",
      "internally developed non-public benchmarks, such as HiddenMath.\n",
      "Model\n",
      "AI Studio model ID\n",
      "Gemini 1.5 Flash\n",
      "gemini-1.5-flash-002\n",
      "Gemini 1.5 Pro\n",
      "gemini-1.5-pro-002\n",
      "Gemini 2.0 Flash-Lite\n",
      "gemini-2.0-flash-lite-001\n",
      "Gemini 2.0 Flash\n",
      "gemini-2.0-flash-001\n",
      "Gemini 2.5 Flash\n",
      "gemini-2.5-flash\n",
      "Gemini 2.5 Pro\n",
      "gemini-2.5-pro\n",
      "Table 2 | Mapping of Gemini model names to AI Studio API model IDs.\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "--- Page 12 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "3.1. Methodology\n",
      "In Table 3, we compare the performance of Gemini 2.5 models to the Gemini 1.5 models, while in\n",
      "Table 4, we compare the performance of Gemini 2.5 Pro to that of other large language models.\n",
      "Gemini results: All Gemini scores are pass@1, and are “single attempt” settings unless otherwise\n",
      "specified. In the “single attempt” setting, no majority voting or parallel test-time compute is permitted,\n",
      "while in the “multiple attempts” setting, test-time selection of the candidate answer is allowed. All\n",
      "Gemini evaluations are run with the AI Studio API for the model id that we provide in Table 2, with\n",
      "default sampling settings. To reduce variance, we average over multiple trials for smaller benchmarks.\n",
      "Aider Polyglot scores are the pass rate average of 3 trials. Vibe-Eval results are reported using Gemini\n",
      "as a judge.\n",
      "Non-Gemini results: All the results for non-Gemini models are sourced from providers’ self\n",
      "reported numbers unless mentioned otherwise. All “SWE-bench Verified” numbers follow official\n",
      "provider reports, which means that they are computed using different scaffoldings and infrastructure,\n",
      "and aren’t directly comparable.\n",
      "For some evaluations, we obtain results from the external leaderboards that report results on\n",
      "these benchmarks. Results for Humanity’s Last Exam results are sourced from Scale’s leaderboard\n",
      "and results for DeepSeek are obtained from the text-only variant of the leaderboard (indicated with a\n",
      "⋄ in Table 4). For Gemini 2.0 models, the reported results are on an earlier HLE dataset (indicated\n",
      "with a † in Table 3). Results on LiveCodeBench results are taken from (1/1/2025 - 5/1/2025) in the\n",
      "UI. Aider Polyglot numbers come from the Aider leaderboard and results for SimpleQA come from\n",
      "this repo where available. Results on FACTS Grounding come from Kaggle. In the case of LOFT and\n",
      "MRCR-V2, we report results on both the 128k context length variant, as well as the 1M context length\n",
      "variant. In the 128k context length variant, we measure performance on contexts up to 128k, while\n",
      "for the 1M context length variant, we report performance on context lengths of exactly 1M.\n",
      "More details on all benchmarks, including subsets and how scores were obtained can be found in\n",
      "Table 11 in Appendix 8.1.\n",
      "3.2. Core capability quantitative results\n",
      "As can be seen in Table 3, and Figure 5, the Gemini 2.5 models excel at coding tasks such as\n",
      "LiveCodeBench, Aider Polyglot and SWE-bench Verified, and represent a marked improvement over\n",
      "previous models.\n",
      "In addition to coding performance, Gemini 2.5 models are noticeably better at math and reasoning\n",
      "tasks than Gemini 1.5 models: performance on AIME 2025 is 88.0% for Gemini 2.5 Pro compared to\n",
      "17.5% for Gemini 1.5 Pro, while performance on GPQA (diamond) went from 58.1% for Gemini 1.5\n",
      "Pro to 86.4%. Performance on image understanding tasks has also increased significantly.\n",
      "It is also interesting to note that the Gemini 2.5 Flash model has become the second most capable\n",
      "model in the Gemini family, and has overtaken not just previous Flash models, but also the Gemini\n",
      "1.5 Pro model released one year ago.\n",
      "12\n",
      "\n",
      "\n",
      "\n",
      "--- Page 13 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "Capability\n",
      "Benchmark\n",
      "Flash\n",
      "Gemini 1.5\n",
      "Pro\n",
      "Gemini 1.5\n",
      "Flash-Lite\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.5\n",
      "Pro\n",
      "Gemini 2.5\n",
      "Code\n",
      "LiveCodeBench\n",
      "30.3%\n",
      "29.7%\n",
      "29.1%\n",
      "29.1%\n",
      "59.3%\n",
      "74.2%\n",
      "Aider Polyglot\n",
      "2.8%\n",
      "16.9%\n",
      "10.5%\n",
      "21.3%\n",
      "56.7%\n",
      "82.2%\n",
      "Verified\n",
      "SWE-bench\n",
      "attempt\n",
      "single\n",
      "9.6%\n",
      "22.3%\n",
      "12.5%\n",
      "21.4%\n",
      "48.9%\n",
      "59.6%\n",
      "attempts\n",
      "multiple\n",
      "19.7%\n",
      "34.2%\n",
      "23.1%\n",
      "34.2%\n",
      "60.3%\n",
      "67.2%\n",
      "Reasoning\n",
      "(diamond)\n",
      "GPQA\n",
      "50.0%\n",
      "58.1%\n",
      "50.5%\n",
      "65.2%\n",
      "82.8%\n",
      "86.4%\n",
      "Last Exam\n",
      "Humanity’s\n",
      "no tools\n",
      "-\n",
      "4.6%\n",
      "4.6% †\n",
      "5.1% †\n",
      "11.0%\n",
      "21.6%\n",
      "Factuality\n",
      "SimpleQA\n",
      "8.6%\n",
      "24.9%\n",
      "16.5%\n",
      "29.9%\n",
      "26.9%\n",
      "54.0%\n",
      "Grounding\n",
      "FACTS\n",
      "82.9%\n",
      "80.0%\n",
      "82.4%\n",
      "84.6%\n",
      "85.3%\n",
      "87.8%\n",
      "Multilinguality\n",
      "(Lite)\n",
      "Global MMLU\n",
      "72.5%\n",
      "80.8%\n",
      "78.0%\n",
      "83.4%\n",
      "88.4%\n",
      "89.2%\n",
      "ECLeKTic\n",
      "16.4%\n",
      "27.0%\n",
      "27.7%\n",
      "33.6%\n",
      "36.8%\n",
      "46.8%\n",
      "Math\n",
      "AIME 2025\n",
      "14.7%\n",
      "17.5%\n",
      "23.8%\n",
      "29.7%\n",
      "72.0%\n",
      "88.0%\n",
      "HiddenMath-\n",
      "Hard\n",
      "36.8%\n",
      "44.3%\n",
      "47.4%\n",
      "53.7%\n",
      "75.5%\n",
      "80.5%\n",
      "Long-context\n",
      "retrieval)\n",
      "LOFT (hard\n",
      "≤128K\n",
      "67.3%\n",
      "75.9%\n",
      "50.7%\n",
      "58.0%\n",
      "82.1%\n",
      "87.0%\n",
      "1M\n",
      "36.7%\n",
      "47.1%\n",
      "7.6%\n",
      "7.6%\n",
      "58.9%\n",
      "69.8%\n",
      "(8-needle)\n",
      "MRCR-V2\n",
      "≤128K\n",
      "18.4%\n",
      "26.2%\n",
      "11.6%\n",
      "19.0%\n",
      "54.3%\n",
      "58.0%\n",
      "1M\n",
      "10.2%\n",
      "12.1%\n",
      "4.0%\n",
      "5.3%\n",
      "21.0%\n",
      "16.4%\n",
      "Understanding\n",
      "Image\n",
      "MMMU\n",
      "58.3%\n",
      "67.7%\n",
      "65.1%\n",
      "69.3%\n",
      "79.7%\n",
      "82.0%\n",
      "(Reka)\n",
      "Vibe-Eval\n",
      "52.3%\n",
      "55.9%\n",
      "51.5%\n",
      "55.4%\n",
      "65.4%\n",
      "67.2%\n",
      "ZeroBench\n",
      "0.5%\n",
      "1.0%\n",
      "0.75%\n",
      "1.25%\n",
      "2.0%\n",
      "4.5%\n",
      "BetterChartQA\n",
      "59.0%\n",
      "65.8%\n",
      "52.3%\n",
      "57.8%\n",
      "67.3%\n",
      "72.4%\n",
      "Table 3 | Evaluation of Gemini 2.5 family across a wide range of core capability benchmarks and in\n",
      "comparison to Gemini 1.5 models. Please see Tables 5 and 6 for audio and video evaluations. See\n",
      "Table 11 Appendix 8.1 for benchmarks and evaluation details.\n",
      "13\n",
      "\n",
      "\n",
      "\n",
      "--- Page 14 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "3.3. Evaluation of Gemini 2.5 Pro against other large language models\n",
      "Relative to other large language models that are available (see Table 4), Gemini achieves the highest\n",
      "score on the Aider Polyglot coding task, Humanity’s Last Exam, GPQA (diamond), and on the SimpleQA\n",
      "and FACTS Grounding factuality benchmarks out of all of the models examined here. Gemini also\n",
      "continues to stand out for achieving the SoTA score on both the LOFT and MRCR long-context tasks\n",
      "at 128k context, and is the only one, amongst the models examined in the above table, to support\n",
      "context lengths of 1M+ tokens.\n",
      "Not all of the models shown in Table 4 have native support for multimodal inputs. As such, we\n",
      "compare against a different set of models for audio and video understanding.\n",
      "Audio Understanding\n",
      "In Table 5, we showcase the performance of the Gemini 2.5 model family at audio understanding,\n",
      "and compare the performance of these models to earlier Gemini models, as well as to GPT models.\n",
      "Gemini 2.5 Pro demonstrates state-of-the-art audio understanding performance as measured by public\n",
      "benchmarks for ASR and AST, and compares favorably to alternatives under comparable testing\n",
      "conditions (using the same prompts and inputs).\n",
      "Video Understanding\n",
      "In Table 6, we show the performance of Gemini 2.5 models at video understanding. As can be\n",
      "seen, Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks,\n",
      "surpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video\n",
      "Capability\n",
      "Benchmark\n",
      "Pro\n",
      "Gemini 2.5\n",
      "high\n",
      "o3\n",
      "high\n",
      "o4-mini\n",
      "Sonnet\n",
      "Claude 4\n",
      "Opus\n",
      "Claude 4\n",
      "Extended Thinking\n",
      "Grok 3 Beta\n",
      "0528\n",
      "DeepSeek R1\n",
      "Code\n",
      "LiveCodeBench\n",
      "74.2%\n",
      "72.0%\n",
      "75.8%\n",
      "48.9%\n",
      "51.1%\n",
      "–\n",
      "70.5%\n",
      "Aider Polyglot\n",
      "82.2%\n",
      "79.6%\n",
      "72.0%\n",
      "61.3%\n",
      "72.0%\n",
      "53.3%\n",
      "71.6%\n",
      "Verified\n",
      "SWE-bench\n",
      "attempt\n",
      "single\n",
      "59.6%\n",
      "69.1%\n",
      "68.1%\n",
      "72.7%\n",
      "72.5%\n",
      "-\n",
      "-\n",
      "attempts\n",
      "multiple\n",
      "67.2%\n",
      "-\n",
      "-\n",
      "80.2%\n",
      "79.4%\n",
      "-\n",
      "57.6%\n",
      "Reasoning\n",
      "(diamond)\n",
      "GPQA\n",
      "attempt\n",
      "single\n",
      "86.4%\n",
      "83.3%\n",
      "81.4%\n",
      "75.4%\n",
      "79.6%\n",
      "80.2%\n",
      "81.0%\n",
      "Last Exam\n",
      "Humanity’s\n",
      "tools\n",
      "no\n",
      "21.6%\n",
      "20.3%\n",
      "18.1%\n",
      "7.8%\n",
      "10.7%\n",
      "-\n",
      "14.0% ⋄\n",
      "Factuality\n",
      "SimpleQA\n",
      "54.0%\n",
      "48.6%\n",
      "19.3%\n",
      "-\n",
      "-\n",
      "43.6%\n",
      "27.8%\n",
      "Grounding\n",
      "FACTS\n",
      "87.8%\n",
      "69.9%\n",
      "62.1%\n",
      "79.1%\n",
      "77.7%\n",
      "74.8%\n",
      "82.4%\n",
      "Math\n",
      "AIME 2025\n",
      "attempt\n",
      "single\n",
      "88.0%\n",
      "88.9%\n",
      "92.7%\n",
      "70.5%\n",
      "75.5%\n",
      "77.3%\n",
      "87.5%\n",
      "Long-context\n",
      "retrieval)\n",
      "LOFT (hard\n",
      "≤128K\n",
      "87.0%\n",
      "77.0%\n",
      "60.5%\n",
      "81.6%\n",
      "-\n",
      "73.1%\n",
      "-\n",
      "1M\n",
      "69.8%\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "(8-needle)\n",
      "MRCR-V2\n",
      "≤128K\n",
      "58.0%\n",
      "57.1%\n",
      "36.3%\n",
      "39.1%\n",
      "16.1%*\n",
      "34.0%\n",
      "-\n",
      "1M\n",
      "16.4%\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Understanding\n",
      "Image\n",
      "MMMU\n",
      "attempt\n",
      "single\n",
      "82.0%\n",
      "82.9%\n",
      "81.6%\n",
      "74.4%\n",
      "76.5%\n",
      "76.0%\n",
      "No MM support\n",
      "Table 4 | Performance comparison of Gemini 2.5 Pro with other large language models on different\n",
      "capabilities. Please see Tables 5 and 6 for audio and video evaluations. See Table 11 for benchmarks\n",
      "and evaluation details. *: with no thinking and API refusals\n",
      "14\n",
      "\n",
      "\n",
      "\n",
      "--- Page 15 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "Benchmark\n",
      "Flash\n",
      "Gemini 1.5\n",
      "Pro\n",
      "Gemini 1.5\n",
      "Flash-Lite\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.5\n",
      "Pro\n",
      "Gemini 2.5\n",
      "Audio Preview\n",
      "GPT-4o mini\n",
      "Audio Preview\n",
      "GPT 4o\n",
      "transcribe\n",
      "GPT 4o\n",
      "(53 lang, WER ↓)\n",
      "FLEURS\n",
      "12.71\n",
      "7.14\n",
      "9.60\n",
      "9.04\n",
      "9.95\n",
      "6.66\n",
      "19.52\n",
      "12.16\n",
      "8.17\n",
      "(21 lang, BLEU ↑)\n",
      "CoVoST2\n",
      "34.81\n",
      "37.53\n",
      "34.74\n",
      "36.35\n",
      "36.15\n",
      "38.48\n",
      "29.5\n",
      "35.89\n",
      "–\n",
      "Table 5 | Performance comparison of Gemini 2.5 models to earlier Gemini models, as well as to GPT\n",
      "models for audio understanding. Note that for GPT models, metrics may differ from those previously\n",
      "reported due to differing eval methodologies. See Table 11 for benchmarks and evaluation details.\n",
      "frames). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative.\n",
      "Modalities\n",
      "Benchmark\n",
      "Flash\n",
      "Gemini 1.5\n",
      "Pro\n",
      "Gemini 1.5\n",
      "Flash-Lite\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.0\n",
      "Flash\n",
      "Gemini 2.5\n",
      "Pro\n",
      "Gemini 2.5\n",
      "GPT 4.1\n",
      "OpenAI\n",
      "visual-only\n",
      "ActivityNet-QA\n",
      "56.2\n",
      "57.3\n",
      "55.3\n",
      "56.4\n",
      "65.1\n",
      "66.7\n",
      "60.4\n",
      "EgoTempo\n",
      "34.5\n",
      "36.3\n",
      "30.1\n",
      "39.3\n",
      "36.7\n",
      "44.3\n",
      "40.3\n",
      "Perception Test\n",
      "66.5\n",
      "69.4\n",
      "67.5\n",
      "68.8\n",
      "75.1\n",
      "78.4\n",
      "64.8\n",
      "QVHighlights\n",
      "64.4\n",
      "68.7\n",
      "25.7\n",
      "63.9\n",
      "52.4\n",
      "75.0\n",
      "71.4\n",
      "VideoMMMU\n",
      "64.8\n",
      "70.4\n",
      "64.3\n",
      "68.5\n",
      "79.2\n",
      "83.6\n",
      "60.9\n",
      "1H-VideoQA\n",
      "61.9\n",
      "72.2\n",
      "55.6\n",
      "67.5\n",
      "67.5\n",
      "81.0\n",
      "56.8\n",
      "audio + visual\n",
      "LVBench\n",
      "61.9\n",
      "65.7\n",
      "52\n",
      "61.8\n",
      "62.7\n",
      "78.7\n",
      "63.4\n",
      "VideoMME\n",
      "70.4\n",
      "73.2\n",
      "62.1\n",
      "72.8\n",
      "75.5\n",
      "84.3\n",
      "72.0\n",
      "VATEX\n",
      "56.9\n",
      "55.5\n",
      "58.5\n",
      "56.9\n",
      "65.2\n",
      "71.3\n",
      "64.1\n",
      "VATEX-ZH\n",
      "46.2\n",
      "52.2\n",
      "43.2\n",
      "48.5\n",
      "43.9\n",
      "59.7\n",
      "48.7\n",
      "YouCook2 Cap\n",
      "153.2\n",
      "170.0\n",
      "78.6\n",
      "129.0\n",
      "177.6\n",
      "188.3\n",
      "127.6\n",
      "visual + subtitles\n",
      "Minerva\n",
      "49.6\n",
      "52.8\n",
      "46.8\n",
      "52.4\n",
      "60.7\n",
      "67.6\n",
      "54.0\n",
      "Neptune\n",
      "78.7\n",
      "82.7\n",
      "81.5\n",
      "83.1\n",
      "84.3\n",
      "87.3\n",
      "85.2\n",
      "subtitles\n",
      "audio+visual+\n",
      "VideoMME\n",
      "77.3\n",
      "79.8\n",
      "72.5\n",
      "78.8\n",
      "81.5\n",
      "86.9\n",
      "79.6\n",
      "Table 6 | Evaluation of Gemini 2.5 vs. prior models and GPT 4.1 on video understanding benchmarks.\n",
      "Performance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracy\n",
      "for open-ended VideoQA, R1@0.5 for moment retrieval and CIDEr for captioning. See Table 11 for\n",
      "benchmarks and evaluation details.\n",
      "15\n",
      "\n",
      "\n",
      "\n",
      "--- Page 16 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "4. Example use cases of Gemini 2.5 Pro\n",
      "4.1. Gemini Plays Pokémon\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "Time Elapsed (Hours)\n",
      "Rival 1 (Oak's Lab)\n",
      "Viridian City\n",
      "Enter Viridian Forest (1st)\n",
      "Exit Viridian Forest (1st)\n",
      "Boulder Badge\n",
      "Enter Mt. Moon (1st)\n",
      "Exit Mt. Moon (1st)\n",
      "Rival 3 (Nugget Bridge)\n",
      "Cascade Badge\n",
      "Bill’s House\n",
      "Rival 4 (SS Anne)\n",
      "Access Pokemon w/ CUT\n",
      "Acquire HM05 Flash\n",
      "Thunder Badge\n",
      "Enter Rock Tunnel (1st)\n",
      "Access Pokemon w/ Flash\n",
      "Exit Rock Tunnel & Reach Lavender Town (1st)\n",
      "Rival 5 (Lavender Tower)\n",
      "Enter Celadon City (1st)\n",
      "Enter Rocket Hideout (1st)\n",
      "Rocket Boss 1 (Rocket Hideout)\n",
      "Rainbow Badge\n",
      "Acquire PokéFlute (Rescue Fuji)\n",
      "Enter Fuchsia City (1st)\n",
      "Enter Safari Zone (1st)\n",
      "Acquire HM03 Surf (Beat Safari Zone)\n",
      "Soul Badge\n",
      "Acquire HM04 Strength (Warden's Teeth)\n",
      "Enter Saffron City (1st)\n",
      "Enter Silph Co. (1st)\n",
      "Rival 6 (Silph Co.)\n",
      "Rocket Boss 2 (Silph Co.)\n",
      "Marsh Badge\n",
      "Enter Cinnabar Island (1st)\n",
      "Acquire Secret Key (Pokemon Mansion)\n",
      "Volcano Badge\n",
      "Earth Badge\n",
      "Rival 7 (Route 22 #2)\n",
      "Enter Victory Road (1st)\n",
      "Exit Victory Road (1st)\n",
      "Beat Elite Four Lorelei\n",
      "Beat Elite Four Bruno\n",
      "Beat Elite Four Agatha\n",
      "Beat Elite Four Lance\n",
      "Hall of Fame\n",
      "Game Milestones\n",
      "Gemini 2.5 Pro Plays Pokemon Progress Timeline\n",
      "Run 1\n",
      "Run 2 (Actual)\n",
      "Figure 6 | Progression of the Gemini Plays Pokémon agent through the game, across two runs. Run 1\n",
      "was the development run where changes to the harness were performed. Run 2 is the fully autonomous\n",
      "run with the final fixed scaffold. Both runs have the same starter (Squirtle). The events are ordered on\n",
      "the y-axis by the order they happened, following the order of Run 2 when there is a conflict. Notably,\n",
      "the GPP agent additionally went through the difficult (and optional) Seafoam Islands dungeon in Run\n",
      "2, while in Run 1, GPP reached Cinnabar Island via Pallet Town and Route 21.\n",
      "On March 28, 2025, an independent developer not affiliated with Google, Joel Zhang, set up a\n",
      "Twitch stream (Gemini Plays Pokémon, or GPP) for Gemini 2.5 Pro (Gemini 2.5 Pro Exp 03-25) to\n",
      "play Pokémon Blue on stream (Zhang, 2025) as an experiment to better understand how well the\n",
      "model was capable of playing Pokémon (in a similar spirit to Claude Plays Pokémon, see Anthropic\n",
      "2025). In this initial run through the game, the goal was to live-stream the development process of\n",
      "an agentic harness capable of playing the full game (and in particular the minimal transformation of\n",
      "vision to text necessary to do so), see Figure 14 for a description of the final agent setup. As such, over\n",
      "the course of the run, modifications were made to the setup as difficulties arose, providing a deeply\n",
      "interesting lens via which to analyze some of the qualitative improvements that the 2.5 Pro model has\n",
      "made, particularly in the regimes of solving long reasoning problems and agentic capabilities over\n",
      "extended time horizons. Around 1 month later, on May 2, 2025, Gemini 2.5 Pro completed the game\n",
      "after 813 hours and entered the Hall of Fame to become the Pokémon League Champion! On May\n",
      "22, 2025, GPP began a fully autonomous 2nd run through the game with Gemini 2.5 Pro (Gemini\n",
      "2.5 Pro Preview 05-06) with the finalized fixed agentic harness, and progressed through the game\n",
      "considerably faster, completing the game in 406.5 hours (nearly exactly half the time of the first run).\n",
      "16\n",
      "\n",
      "\n",
      "\n",
      "Saved image: extracted_images\\page16_img0.png\n",
      "Saved image: extracted_images\\page16_img1.png\n",
      "--- Page 17 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "See Figure 6 for a timeline of GPP’s progress through major game milestones to game completion.\n",
      "We report # hours to each milestone in order to normalize for the amount of time models take per\n",
      "action. See Appendix 8.2 for more figures.\n",
      "Capabilities assessment\n",
      "Gemini 2.5 Pro showcased many impressive capabilities associated with reasoning and long-term\n",
      "planning while playing Pokémon. We will now discuss two in particular, but for more examples, see\n",
      "Appendix 8.2.\n",
      "Long Context Agentic Tooling\n",
      "Within the agent scaffolding, GPP has access to two agentic\n",
      "tools (see Figure 14). These prompted versions of Gemini 2.5 Pro, hereafter pathfinder and\n",
      "boulder_puzzle_strategist, have been able to:\n",
      "1. Solve complex spinner puzzles in one shot (for instance in Rocket Hideout),\n",
      "2. Solve the step-constrained multi-map puzzle of the Safari Zone,\n",
      "3. Find long pathways through complex mazes like Route 13,\n",
      "4. Solve boulder puzzles across long distances in Victory Road and the Seafoam Islands.\n",
      "Each task requires reasoning over a long context - the pathfinder model would often have to reason\n",
      "over contexts of 100K+ tokens, and find paths up to 50 actions in length (in the extreme case, paths\n",
      "consisting of up to 150 actions have also been found!).\n",
      "Long Horizon Task Coherence\n",
      "While Gemini 2.5 Pro is impressive in a more local sense, the agent\n",
      "also exhibited remarkable long-term task coherence in achieving global, high-level goals in the face of\n",
      "real and hallucinated setbacks towards making forward progress. Because the agent is able to change\n",
      "goals at will, and will generally follow those goals as long as needed, it is extremely impressive that\n",
      "the agent can satisfy numerous requirements for tactical, necessary goals, such as acquiring Hidden\n",
      "Moves, as well as maintain enough strategic task coherence to beat the entire game and become the\n",
      "Pokémon Champion.\n",
      "Where does 2.5 Pro struggle while playing Pokémon?\n",
      "In addition to more standard hallucination issues (which interestingly were plausibly reduced in Run\n",
      "2 by explicitly prompting the model to act as a player completely new to the game, see Appendix 8.2\n",
      "for more details), there are a few particular points of struggle we would like to emphasize.\n",
      "Screen reading\n",
      "While obtaining excellent benchmark numbers on real-world vision tasks, 2.5 Pro\n",
      "struggled to utilize the raw pixels of the Game Boy screen directly, though it could occasionally take\n",
      "cues from information on the pixels. As a result, it was necessary for the required information from\n",
      "the screen to be translated into a text format in the agent framework, using information from the\n",
      "game’s RAM state. During one portion of the game, the developer tested an ablation where all vision\n",
      "was completely removed from the model context – the model was able to function roughly as well\n",
      "as without the vision information, suggesting that most of the performance does not significantly\n",
      "depend on the visual input.\n",
      "Long Context Reasoning\n",
      "Gemini 2.5 Pro’s state-of-the-art long context performance for both\n",
      "reasoning and retrieval tasks (see Tables 3 and 4) was a cornerstone of the GPP agent’s success. Its\n",
      "ability to reason over a 100k token context was instrumental for leveraging the complex toolset and\n",
      "17\n",
      "\n",
      "\n",
      "\n",
      "--- Page 18 Text ---\n",
      "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.\n",
      "maintaining a relatively coherent strategy (e.g., optimal balance of performance, planning quality,\n",
      "and information recall.)\n",
      "While Gemini 2.5 Pro supports 1M+ token context, making effective use of it for agents presents\n",
      "a new research frontier. In this agentic setup, it was observed that as the context grew significantly\n",
      "beyond 100k tokens, the agent showed a tendency toward favoring repeating actions from its vast\n",
      "history rather than synthesizing novel plans. This phenomenon, albeit anecdotal, highlights an\n",
      "important distinction between long-context for retrieval and long-context for multi-step, generative\n",
      "reasoning.\n",
      "Teaching an agent to effectively plan and avoid such loops over massive past trajectories of context\n",
      "is an exciting and active area of research; the co-design of agent scaffolds and models to unlock the\n",
      "full potential of million-token context is an intriguing research direction and one of our primary\n",
      "focuses.\n",
      "4.2. What else can Gemini 2.5 do?\n",
      "Gemini 2.5 Pro excels at transforming diverse, often unstructured, inputs into interactive and func-\n",
      "tional applications. For instance, it can take a PDF script of a play and generate a tool that allows\n",
      "drama students to practice their lines. Gemini 2.5 Pro can also take an uploaded photograph of a\n",
      "bookshelf and create a curated book recommendation application. Gemini 2.5 Pro can utilize its\n",
      "underlying spatial understanding capability and convert images into a structural representation like\n",
      "HTML or SVG. In Figure 16 in Appendix 8.4, we show a comparison of Gemini 1.5 Pro and Gemini\n",
      "2.5 Pro on an image-to-svg task, where Gemini 2.5 Pro reconstructs much more visual details and the\n",
      "spatial arrangements of objects better resembles the original image.\n",
      "Furthermore, Gemini 2.5 Pro demonstrates strong skills in generating sophisticated simulations\n",
      "and visualizations, ranging from interactive solar system models (source) to the creative rendering of\n",
      "abstract mathematical concepts, such as drawing a logo using Fourier series (source). This capability\n",
      "extends to the development of tools that intersect creativity and utility: we see examples of specialized\n",
      "applications like a custom cartography tool or use cases that generate photorealistic 3D user interfaces\n",
      "from descriptive text and reference images, complete with appropriate styling and interactivity\n",
      "(source).\n",
      "Collectively, these examples illustrate that Gemini 2.5 Pro is not just a useful coding and writing\n",
      "assistant, but excels at a wide range of complex tasks, ranging from those relevant for education\n",
      "to creative expression. The model empowers users to rapidly prototype specialized utilities, de-\n",
      "velop engaging educational content, and realize intricate creative visions with a high degree of\n",
      "sophistication.\n",
      "4.3. Gemini in Google Products\n",
      "As a final example of what Gemini can do, we note that Gemini (or a custom version of Gemini) is\n",
      "now incorporated into a wide variety of Google products. These include, but are not limited to, AI\n",
      "Overviews and AI Mode within Google Search, Project Astra, the audiovisual-to-audio dialog agent,\n",
      "Gemini Deep Research, the research assistant discussed in Section 2.7, NotebookLM, the tool capable\n",
      "of generating podcasts and audio overviews from even the most obscure inputs, Project Mariner, the\n",
      "web browsing agent, and Google’s coding agent, Jules.\n",
      "18\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_pdf_content(pdf_path, output_image_dir=\"extracted_images\"):\n",
    "    try:\n",
    "        document = fitz.open(pdf_path)\n",
    "        \n",
    "        # Create directory for images if it doesn't exist\n",
    "        if not os.path.exists(output_image_dir):\n",
    "            os.makedirs(output_image_dir)\n",
    "\n",
    "        for page_num in range(min(18, len(document))):\n",
    "            page = document.load_page(page_num)\n",
    "            \n",
    "            # Extract text\n",
    "            text = page.get_text()\n",
    "            print(f\"--- Page {page_num + 1} Text ---\")\n",
    "            print(text)\n",
    "            print(\"\\n\")\n",
    "\n",
    "            # Extract images\n",
    "            image_list = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(image_list):\n",
    "                xref = img[0]\n",
    "                base_image = document.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_ext = base_image[\"ext\"]\n",
    "                image_filename = os.path.join(output_image_dir, f\"page{page_num + 1}_img{img_index}.{image_ext}\")\n",
    "                with open(image_filename, \"wb\") as img_file:\n",
    "                    img_file.write(image_bytes)\n",
    "                print(f\"Saved image: {image_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"data/gemini-2.5-tech.pdf\"\n",
    "    extract_pdf_content(pdf_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
